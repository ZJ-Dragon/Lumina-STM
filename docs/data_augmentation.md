<!--
  Luminaâ€‘STM | Data Augmentation Handbook
  ======================================
  This document explains *why* and *how* we augment RAWâ€‘tensor data for both
  Transformer and Diffusion branches, and offers practical tuning advice.
-->

## Overview

Luminaâ€‘STM trains on linearâ€‘HDR tensors whose numeric range spans **0â€¯â€“â€¯4**â€¯EV.
To prevent overâ€‘fitting and make the network robust to exposure mistakes, whiteâ€‘balance drift and sensor noise, we adopt *two* complementary augmentation paths:

| Mode | When applied | Saved to disk? | Typical useâ€‘case |
|------|--------------|----------------|------------------|
| **Offline** | Once, right after preprocessing | âœ”Â `datasets/pipeline/aug_train/` | Largeâ€‘scale training on fixed clusters (less CPU load during epochs) |
| **Online** | Onâ€‘theâ€‘fly inside `Dataset.__getitem__` | âœ– | Rapid prototyping or overfitâ€‘checks on a small sample set |

The same YAML (`configs/augmentations.yaml`) governs *both* modes, ensuring identical math and parameter spaces.

---

## 1. Algorithmic Principles

### 1.1 ExposureÂ Shift  
Camera exposure errors translate to a scalar gain *GÂ =Â 2^EV*.  
We sample **EVâ€¯âˆˆâ€¯[â€“2,Â +2]** (configurable) and clip back to `0â€“4` afterwards, preserving highlight rollâ€‘off.

### 1.2 Whiteâ€‘BalanceÂ Jitter  
We multiply R & B channels by gains sampled from **[0.9,â€¯1.1]** while keeping G constant.  
This teaches the network to handle atypical CCTs without colour casts in the output.

### 1.3 Toneâ€‘CurveÂ Perturbation  
A lightâ€‘weight toe/shoulder modification:  
```text
if x > pivot:  y = pivot + slope Â· (xÂ â€“Â pivot)
else:          y = x
```  
Parameters **pivotâ€¯âˆˆâ€¯[0.3,Â 0.7]**, **slopeâ€¯âˆˆâ€¯[0.8,Â 1.2]** emulate different inâ€‘camera tone profiles yet remain invertible.

### 1.4 Noise Injection  
We add *white* Gaussian noise (Ïƒ range **5â€¯eâ€‘4Â â€“Â 1â€¯eâ€‘2**) plus an optional chromaâ€‘correlated term (ratio â‰¤â€¯0.5).  
This mimics sensor/ISP patterns while keeping SNR realistic for RAW space.

### 1.5 Geometric & Blur  
Horizontal flip (50â€¯%) and mild Gaussian blur (Ïƒ **0.2â€“1.0â€¯px**) enrich local texture statistics without hurting Bayer alignment.  
Vertical flip is disabled by default to keep orientation metadata intact, but can be toggled in YAML.

---

## 2. Offline Workflow

```
raw_master/*.npy        â”
                        â”‚
        gen_aug_train.pyâ”‚  (multiprocess)
                        â–¼
aug_train/*.npy         â”˜
```

1. **Trigger**:  
   ```bash
   python scripts/raw_preprocess.py --cfg ... --augment offline -j 8
   ```
2. **Determinism**: Each file gets a seed derived from its filename hash â†’ output is fully reproducible via DVC (`dvc repro augment_train`).
3. **Storage Footprint**: Expect Ã—1.0â€¯â€“â€¯1.3 disk growth vs. `raw_master` depending on enabled transforms.

---

## 3. Online Workflow

1. `RawTensorDataset` builds the pipeline once per worker using `build_pipeline(cfg, mode="online")`.
2. During `__getitem__`, the pipeline is executed **after** whiteâ€‘balance jitter and **before** Tensor â†’ Torch conversion.
3. Set in the dataloader config:
   ```yaml
   use_augmentation: true
   augmentation_cfg: configs/augmentations.yaml
   ```
4. Useful for quick hyperâ€‘parameter sweeps where CPU overhead is negligible compared to GPU idling.

---

## 4. Tuning Guide

| Symptom | Likely Fix | YAML Knob |
|---------|-----------|-----------|
| Model overâ€‘exposes highlights | Increase **pivot** upper bound or reduce **slope** | `curve_perturb.pivot_range` / `slope_range` |
| Colour cast on daylight shots | Narrow **rgb_gain_range** to around [0.95,Â 1.05] | `white_balance_jitter.rgb_gain_range` |
| Training diverges early | Lower **EV range** to Â±1 | `exposure_shift.ev_range` |
| Too smooth / lack detail | Disable **gaussian_blur** or drop its `p` to 0.1 | `gaussian_blur.p`, `sigma_range` |
| GPU underâ€‘utilised (online mode) | Switch to **offline** and regenerate `aug_train/` once | CLI `--augment offline` |

> **Tip:** Always run `pytest -k augment` after tweaking YAML to catch outâ€‘ofâ€‘range params early.

---

## 5. Future Extensions

* **Hue/Sat randomisation** in perceptual colour spaces (e.g. JzAzBz) once we migrate to spectralâ€‘aware training.
* **Learnable LUT** augmentation driven by a small MLP to mimic proprietary film simulations.
* **Synthetic sensor defects** (hot pixels, CFA misâ€‘alignment) gated by hardware model ID.

---

Happy training! ðŸš€ Feel free to open a GitHub issue whenever new augmentation ideas surface.
